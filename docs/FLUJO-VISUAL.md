# ğŸ¨ Flujo Visual del Predictor de Fallas

> Este diagrama se renderiza automÃ¡ticamente en GitHub

```mermaid
graph TD
    Start([ğŸ‘¤ Usuario: service 25]) --> API[ğŸ“¥ API /predict-fallas]
    
    API --> Detect[ğŸ¯ Detectar Contexto<br/>modelo + cÃ³digo error]
    
    Detect --> Search[ğŸ” BÃšSQUEDA HÃBRIDA<br/>SemÃ¡ntica 40% + Keywords 60%<br/>Boost 1.5x iCombi Classic]
    
    Search --> Reranker[ğŸ¤– LLM RE-RANKER<br/>Analiza cada documento<br/>Relevancia 0-100]
    
    Reranker --> Context[ğŸ“ CONSTRUIR CONTEXTO<br/>2000+ chars/doc<br/>Total: 15,000 chars]
    
    Context --> Generate[ğŸ¤– GENERACIÃ“N LLM<br/>GPT-4o-mini<br/>DiagnÃ³stico completo]
    
    Generate --> Enrich[ğŸ“š ENRIQUECIMIENTO<br/>+ Relevancia LLM<br/>+ Explicaciones<br/>+ URLs navegables]
    
    Enrich --> Response[âœ… RESPUESTA JSON<br/>DiagnÃ³stico + 10 docs<br/>+ Links + Signals]
    
    %% Estilos
    classDef inputClass fill:#e1f5ff,stroke:#01579b,stroke-width:2px
    classDef processClass fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef llmClass fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef searchClass fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    classDef outputClass fill:#c8e6c9,stroke:#2e7d32,stroke-width:3px
    
    class Start,API inputClass
    class Detect,Context,Enrich processClass
    class Reranker,Generate llmClass
    class Search searchClass
    class Response outputClass
```

## â±ï¸ Tiempos de EjecuciÃ³n

| Fase | Tiempo |
|------|--------|
| BÃºsqueda HÃ­brida | 1-2 seg |
| LLM Re-Ranker | 5-8 seg |
| ConstrucciÃ³n Contexto | 200 ms |
| GeneraciÃ³n LLM | 2-3 seg |
| **TOTAL** | **8-14 seg** |

## ğŸ¯ Flujo Detallado

```
ğŸ‘¤ Usuario: "Por quÃ© me arroja un service 25"
    â†“
ğŸ“¥ API recibe peticiÃ³n
    â”œâ”€ modelo: "iCombi Classic"
    â””â”€ cÃ³digo: "25"
    â†“
ğŸ” BÃšSQUEDA HÃBRIDA (1-2 seg)
    â”œâ”€ SemÃ¡ntica 40%: embeddings vectoriales
    â”œâ”€ Keywords 60%: "service", "25", "icombi"
    â””â”€ Boost 1.5x: docs de iCombi Classic
    âœ 18 documentos candidatos
    â†“
ğŸ¤– LLM RE-RANKER (5-8 seg)
    â”œâ”€ Analiza cada documento
    â”œâ”€ Asigna relevancia 0-100
    â””â”€ Explica por quÃ© es relevante
    âœ Top 10 ordenados
    â†“
ğŸ“ CONSTRUCCIÃ“N CONTEXTO (200 ms)
    â”œâ”€ Expande a 2000+ chars/doc
    â””â”€ Total: ~15,000 caracteres
    â†“
ğŸ¤– GENERACIÃ“N LLM (2-3 seg)
    â”œâ”€ Fallas probables
    â”œâ”€ Repuestos necesarios
    â”œâ”€ Pasos de reparaciÃ³n
    â””â”€ Referencias citadas
    â†“
ğŸ“š ENRIQUECIMIENTO (100 ms)
    â”œâ”€ Relevancia LLM: 95%
    â”œâ”€ ExplicaciÃ³n del LLM
    â”œâ”€ URL navegable: pdf#page=28
    â””â”€ Metadata completa
    â†“
âœ… RESPUESTA JSON
    â”œâ”€ DiagnÃ³stico detallado
    â”œâ”€ 10 documentos ordenados
    â”œâ”€ Links directos a PDFs
    â””â”€ Signals de calidad
```

## ğŸ“Š Componentes

### BÃºsqueda HÃ­brida ğŸ”
- **Archivo:** `services/kb/demo_kb.py:537-630`
- **FunciÃ³n:** Combina semÃ¡ntica + keywords
- **Resultado:** 18 candidatos en 1-2 seg

### LLM Re-Ranker ğŸ¤–
- **Archivo:** `services/orch/llm_reranker.py`
- **FunciÃ³n:** AnÃ¡lisis semÃ¡ntico profundo
- **Resultado:** Top 10 con explicaciones

### RAG Orquestador ğŸ¨
- **Archivo:** `services/orch/rag.py`
- **FunciÃ³n:** Construye contexto enriquecido
- **Resultado:** Prompt de 15,000 caracteres

### API Principal ğŸ“¥
- **Archivo:** `app/main.py:83-226`
- **FunciÃ³n:** Endpoint `/predict-fallas`
- **Resultado:** JSON estructurado
