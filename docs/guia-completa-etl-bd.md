# ğŸ“˜ GuÃ­a Completa: ETL Inteligente BD â†’ KB

## ğŸ¯ **VisiÃ³n General del Sistema**

Este sistema permite **extraer automÃ¡ticamente** datos de bases de datos MySQL y **transformarlos inteligentemente** usando IA para alimentar el Knowledge Base tÃ©cnico. La IA analiza el contexto de negocio y optimiza la extracciÃ³n para obtener el mÃ¡ximo valor predictivo.

### **ğŸ”„ Flujo Principal:**
```
BD MySQL â†’ Auto-DocumentaciÃ³n â†’ EvaluaciÃ³n IA â†’ ConfiguraciÃ³n ETL â†’ ExtracciÃ³n â†’ TransformaciÃ³n IA â†’ KB Optimizado
```

## ğŸ—ï¸ **Arquitectura del Sistema**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            ğŸ—ï¸ ARQUITECTURA ETL IA                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   BD MySQL  â”‚â”€â”€â”€â–¶â”‚ Context Extractor â”‚â”€â”€â”€â–¶â”‚     Schema Analyzer IA        â”‚ â”‚
â”‚  â”‚             â”‚    â”‚                  â”‚    â”‚                               â”‚ â”‚
â”‚  â”‚ â€¢ services  â”‚    â”‚ â€¢ Business Logic â”‚    â”‚ â€¢ Relevance Scoring           â”‚ â”‚
â”‚  â”‚ â€¢ equipmentsâ”‚    â”‚ â€¢ Data Sampling  â”‚    â”‚ â€¢ Strategy Selection          â”‚ â”‚
â”‚  â”‚ â€¢ customers â”‚    â”‚ â€¢ Relationship   â”‚    â”‚ â€¢ Transformation Planning     â”‚ â”‚
â”‚  â”‚ â€¢ logs      â”‚    â”‚   Detection      â”‚    â”‚ â€¢ Priority Assignment        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                     â”‚                              â”‚                  â”‚
â”‚         â–¼                     â–¼                              â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Manual Configâ”‚    â”‚ AI Configuration â”‚    â”‚      ETL Pipeline              â”‚ â”‚
â”‚  â”‚             â”‚    â”‚                  â”‚    â”‚                               â”‚ â”‚
â”‚  â”‚ â€¢ Business  â”‚â”€â”€â”€â–¶â”‚ â€¢ Table Configs  â”‚â”€â”€â”€â–¶â”‚ â€¢ Incremental Extraction      â”‚ â”‚
â”‚  â”‚   Rules     â”‚    â”‚ â€¢ JOIN Strategiesâ”‚    â”‚ â€¢ AI Transformation           â”‚ â”‚
â”‚  â”‚ â€¢ Prioritiesâ”‚    â”‚ â€¢ Filter Rules   â”‚    â”‚ â€¢ Quality Validation          â”‚ â”‚
â”‚  â”‚ â€¢ Overrides â”‚    â”‚ â€¢ Prompts        â”‚    â”‚ â€¢ KB Ingestion               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                               â”‚                              â”‚                  â”‚
â”‚                               â–¼                              â–¼                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                    â”‚   Monitoring     â”‚    â”‚      Knowledge Base            â”‚ â”‚
â”‚                    â”‚                  â”‚    â”‚                               â”‚ â”‚
â”‚                    â”‚ â€¢ Quality Metricsâ”‚    â”‚ â€¢ Technical Documents          â”‚ â”‚
â”‚                    â”‚ â€¢ Success Rates  â”‚    â”‚ â€¢ Auto-Generated Metadata     â”‚ â”‚
â”‚                    â”‚ â€¢ Error Tracking â”‚    â”‚ â€¢ Searchable & Filtered       â”‚ â”‚
â”‚                    â”‚ â€¢ Performance    â”‚    â”‚ â€¢ Auto-Learning Taxonomy      â”‚ â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š **Paso a Paso: ImplementaciÃ³n Completa**

### **ğŸš€ PASO 1: PreparaciÃ³n del Entorno**

#### **1.1 ConfiguraciÃ³n de Variables de Entorno**

```bash
# Agregar a .env
# ETL Configuration
ETL_ENABLED=true
ETL_INCREMENTAL_HOURS=2
ETL_FULL_SYNC_TIME=02:00
ETL_BATCH_SIZE=500
ETL_RETRY_ATTEMPTS=3

# BD Principal (ya configurada)
MYSQL_HOST=tu-rds.amazonaws.com
MYSQL_PORT=3306
MYSQL_USER=usuario_ro
MYSQL_PASSWORD=******
MYSQL_DATABASE=mi_db

# AI Transformation
ETL_LLM_MODEL=gpt-4o-mini
ETL_LLM_TEMPERATURE=0.1
ETL_MAX_DOCS_PER_BATCH=50

# Quality Monitoring
ETL_QUALITY_THRESHOLD=0.85
ETL_ALERT_EMAIL=admin@company.com
```

#### **1.2 Estructura de Archivos**

```
fixeatAI/
â”œâ”€â”€ services/etl/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context_extractor.py      # Auto-documentaciÃ³n BD
â”‚   â”œâ”€â”€ schema_analyzer.py        # EvaluaciÃ³n IA de tablas
â”‚   â”œâ”€â”€ config_generator.py       # GeneraciÃ³n de configuraciones
â”‚   â”œâ”€â”€ pipeline.py               # Pipeline principal ETL
â”‚   â”œâ”€â”€ scheduler.py              # Programador de tareas
â”‚   â””â”€â”€ monitor.py                # Monitor de calidad
â”œâ”€â”€ configs/etl/
â”‚   â”œâ”€â”€ bd_business_context.json  # Contexto manual de BD
â”‚   â”œâ”€â”€ etl_dynamic_config.json   # ConfiguraciÃ³n generada por IA
â”‚   â””â”€â”€ table_mappings.json       # Mapeos especÃ­ficos
â””â”€â”€ docs/etl/
    â”œâ”€â”€ bd_analysis_report.md     # Reporte de anÃ¡lisis
    â””â”€â”€ implementation_log.md     # Log de implementaciÃ³n
```

### **ğŸ” PASO 2: Auto-DocumentaciÃ³n de la BD**

#### **2.1 Ejecutar Context Extractor**

```bash
# Endpoint para descubrir y documentar BD automÃ¡ticamente
curl -X POST "http://localhost:8000/api/v1/etl/discover-context" | jq .
```

**QuÃ© hace:**
- Introspecciona TODAS las tablas de la BD
- IA analiza nombres, columnas y muestra de datos
- Infiere propÃ³sito de negocio de cada tabla
- Detecta relaciones semÃ¡nticas
- Genera documentaciÃ³n automÃ¡tica

#### **2.2 Revisar DocumentaciÃ³n Generada**

```bash
# Ver anÃ¡lisis completo de contexto
curl "http://localhost:8000/api/v1/etl/context-report" | jq .

# Ver anÃ¡lisis de tabla especÃ­fica
curl "http://localhost:8000/api/v1/etl/table-context/services" | jq .
```

**Ejemplo de Output:**
```json
{
  "database_overview": {
    "business_type": "Servicios tÃ©cnicos de equipos industriales",
    "industry_context": "ReparaciÃ³n y mantenimiento de equipos de panaderÃ­a/cocina",
    "main_entities": ["equipments", "services", "customers", "technicians"],
    "data_flow": "Customer reports issue â†’ Service created â†’ Technician assigned â†’ Resolution documented"
  },
  "table_analysis": {
    "services": {
      "business_purpose": "Ã“rdenes de servicio tÃ©cnico con diagnÃ³sticos y resoluciones",
      "ai_relevance": 9,
      "critical_fields": ["issue_description", "resolution", "parts_used"],
      "relationships": ["equipments.id", "customers.id"],
      "kb_value": "CRÃTICO: Casos reales de falla y resoluciÃ³n para entrenamiento IA"
    }
  }
}
```

#### **2.3 Enriquecer con Contexto Manual**

```bash
# Editar contexto manual especÃ­fico del negocio
nano configs/etl/bd_business_context.json
```

**Complementar con:**
- Reglas de negocio especÃ­ficas
- Definiciones precisas de campos crÃ­ticos
- Prioridades del negocio
- Casos de uso especÃ­ficos

### **ğŸ¤– PASO 3: EvaluaciÃ³n IA de Tablas**

#### **3.1 Ejecutar AnÃ¡lisis IA**

```bash
# IA evalÃºa todas las tablas con contexto completo
curl -X POST "http://localhost:8000/api/v1/etl/analyze-schema" | jq .
```

**QuÃ© evalÃºa la IA:**
- **Relevancia TÃ©cnica (0-10)**: Â¿Ãštil para diagnÃ³stico de equipos?
- **Valor Predictivo (0-10)**: Â¿Ãštil para predecir fallas?
- **Calidad Narrativa (0-10)**: Â¿Datos ricos para contenido tÃ©cnico?
- **Prioridad ETL**: CRÃTICA/ALTA/MEDIA/BAJA
- **Estrategia**: full_table/filtered/joined/enriched

#### **3.2 Revisar Evaluaciones IA**

```bash
# Ver evaluaciÃ³n completa
curl "http://localhost:8000/api/v1/etl/evaluation-report" | jq .

# Dashboard de evaluaciones
curl "http://localhost:8000/api/v1/etl/evaluation-dashboard" | jq .
```

**Ejemplo de EvaluaciÃ³n:**
```json
{
  "services": {
    "relevancia_tecnica": 9,
    "valor_predictivo": 8,
    "calidad_narrativa": 9,
    "prioridad": "CRÃTICA",
    "estrategia": "joined",
    "join_recomendados": ["equipments", "customers"],
    "transformacion": "Narrativa tÃ©cnica completa con contexto de equipo y resoluciÃ³n",
    "razonamiento": "Tabla central del negocio con casos reales de falla y resoluciÃ³n"
  }
}
```

### **âš™ï¸ PASO 4: GeneraciÃ³n de ConfiguraciÃ³n ETL**

#### **4.1 Generar Configuraciones AutomÃ¡ticas**

```bash
# IA genera configuraciÃ³n ETL optimizada
curl -X POST "http://localhost:8000/api/v1/etl/generate-config" | jq .
```

**ConfiguraciÃ³n Generada:**
```json
{
  "services": {
    "enabled": true,
    "priority": "CRÃTICA",
    "extraction": {
      "strategy": "joined",
      "sql_template": "SELECT s.*, e.brand, e.model, e.equipment_type FROM services s JOIN equipments e ON s.equipment_id = e.id",
      "incremental_column": "s.updated_at",
      "where_clause": "WHERE s.status IN ('completed', 'in_progress')",
      "batch_size": 500
    },
    "transformation": {
      "ai_prompt": "services_to_technical_narrative.prompt",
      "metadata_extraction": ["brand", "model", "equipment_type", "issue_type"],
      "quality_filters": {"min_text_length": 100}
    }
  }
}
```

#### **4.2 Revisar y Ajustar ConfiguraciÃ³n**

```bash
# Ver configuraciÃ³n completa generada
curl "http://localhost:8000/api/v1/etl/config" | jq .

# Modificar configuraciÃ³n especÃ­fica
curl -X PUT "http://localhost:8000/api/v1/etl/config/services" \
  -d '{"extraction": {"where_clause": "WHERE status = \"completed\" AND priority = \"high\""}}' | jq .
```

### **ğŸ”„ PASO 5: Ejecutar ETL Pipeline**

#### **5.1 Testing Previo**

```bash
# Probar extracciÃ³n de tabla especÃ­fica (dry run)
curl -X POST "http://localhost:8000/api/v1/etl/test-extraction/services?limit=10&dry_run=true" | jq .

# Ver preview de transformaciÃ³n IA
curl "http://localhost:8000/api/v1/etl/preview-transformation/services?limit=3" | jq .
```

#### **5.2 EjecuciÃ³n Controlada**

```bash
# Ejecutar ETL solo para tablas crÃ­ticas
curl -X POST "http://localhost:8000/api/v1/etl/sync" \
  -d '{"priority_filter": ["CRÃTICA"], "tables": ["services"], "batch_size": 100}' | jq .

# Ejecutar ETL completo
curl -X POST "http://localhost:8000/api/v1/etl/sync-all" | jq .
```

#### **5.3 Monitoreo en Tiempo Real**

```bash
# Ver progreso del ETL
curl "http://localhost:8000/api/v1/etl/status" | jq .

# Ver logs en tiempo real
tail -f logs/etl.log

# MÃ©tricas de calidad
curl "http://localhost:8000/api/v1/etl/metrics" | jq .
```

### **ğŸ“Š PASO 6: ValidaciÃ³n y OptimizaciÃ³n**

#### **6.1 Verificar Resultados en KB**

```bash
# Ver documentos ingresados
curl -X POST "http://localhost:7070/tools/kb_search" \
  -d '{"query": "test", "top_k": 10}' | jq '.hits | length'

# Verificar taxonomÃ­a aprendida
curl "http://localhost:7070/tools/taxonomy/stats" | jq .

# BÃºsqueda especÃ­fica
curl -X POST "http://localhost:7070/tools/kb_search" \
  -d '{"query": "RATIONAL horno problema", "where": {"brand": "RATIONAL"}}' | jq .
```

#### **6.2 Optimizar Configuraciones**

```bash
# Analizar mÃ©tricas de calidad por tabla
curl "http://localhost:8000/api/v1/etl/quality-report" | jq .

# Ajustar configuraciÃ³n basada en resultados
curl -X PUT "http://localhost:8000/api/v1/etl/config/services" \
  -d '{"transformation": {"quality_filters": {"min_text_length": 150}}}' | jq .
```

## ğŸ”„ **Agregar Nueva Base de Datos: Paso a Paso**

### **ğŸ“‹ Caso: Agregar BD de Inventarios**

#### **PASO 1: ConfiguraciÃ³n de ConexiÃ³n**

```bash
# Agregar a .env
# Segunda BD - Inventarios
MYSQL_INVENTORY_HOST=inventarios-rds.amazonaws.com
MYSQL_INVENTORY_PORT=3306
MYSQL_INVENTORY_USER=readonly_user
MYSQL_INVENTORY_PASSWORD=******
MYSQL_INVENTORY_DATABASE=inventarios_db
```

#### **PASO 2: Configurar Cliente MySQL**

```python
# services/db/mysql_inventory.py
class MySQLInventoryClient(MySQLClient):
    def __init__(self):
        # Override para usar variables de inventario
        self.host = os.getenv("MYSQL_INVENTORY_HOST")
        self.user = os.getenv("MYSQL_INVENTORY_USER")
        # ... resto de configuraciÃ³n especÃ­fica
```

#### **PASO 3: Documentar Contexto de Negocio**

```json
// configs/etl/inventarios_business_context.json
{
  "database_metadata": {
    "business_domain": "GestiÃ³n de inventarios y repuestos",
    "industry": "DistribuciÃ³n de repuestos industriales",
    "data_classification": "LogÃ­stica y stock",
    "relationship_with_main_db": "inventory.part_id â†’ main.services.parts_used"
  },
  
  "table_documentation": {
    "parts_inventory": {
      "business_purpose": "Stock actual de repuestos por bodega",
      "critical_fields": {
        "part_number": "CÃ³digo Ãºnico del repuesto - CRÃTICO para matching",
        "part_name": "DescripciÃ³n del repuesto - CRÃTICO para IA",
        "equipment_compatibility": "Equipos compatibles - CRÃTICO para predicciÃ³n",
        "stock_quantity": "Cantidad disponible - Ãºtil para alertas",
        "supplier": "Proveedor - contexto adicional"
      },
      "ai_usage": {
        "prediction_enhancement": "Enriquecer predicciones con disponibilidad de repuestos",
        "metadata_source": ["part_number", "equipment_compatibility"],
        "cross_reference": "Vincular con services.parts_used"
      }
    }
  }
}
```

#### **PASO 4: Ejecutar Descubrimiento**

```bash
# Descubrir nueva BD
curl -X POST "http://localhost:8000/api/v1/etl/discover-context" \
  -d '{"database": "inventory", "config_source": "MYSQL_INVENTORY"}' | jq .

# Analizar con IA
curl -X POST "http://localhost:8000/api/v1/etl/analyze-schema" \
  -d '{"database": "inventory"}' | jq .
```

#### **PASO 5: Configurar Relaciones Cross-BD**

```json
// ConfiguraciÃ³n de relaciones entre BDs
{
  "cross_database_relationships": {
    "main_services_to_inventory": {
      "type": "enrichment",
      "source": "main.services.parts_used",
      "target": "inventory.parts_inventory.part_number",
      "purpose": "Enriquecer predicciones con disponibilidad de stock",
      "transformation": "LEFT JOIN para obtener info de stock en predicciones"
    }
  }
}
```

#### **PASO 6: ETL Multi-BD**

```bash
# ETL coordinado entre mÃºltiples BDs
curl -X POST "http://localhost:8000/api/v1/etl/sync-multi-db" \
  -d '{
    "databases": ["main", "inventory"],
    "cross_reference": true,
    "enrichment_mode": true
  }' | jq .
```

## ğŸ› ï¸ **Comandos de AdministraciÃ³n**

### **ğŸ”§ GestiÃ³n Diaria**

```bash
# Estado general del sistema
curl "http://localhost:8000/api/v1/etl/health" | jq .

# Ejecutar sync incremental manual
curl -X POST "http://localhost:8000/api/v1/etl/sync-incremental" | jq .

# Ver Ãºltimas mÃ©tricas
curl "http://localhost:8000/api/v1/etl/dashboard" | jq .

# Pausar/reanudar ETL
curl -X POST "http://localhost:8000/api/v1/etl/pause" | jq .
curl -X POST "http://localhost:8000/api/v1/etl/resume" | jq .
```

### **ğŸ” Debugging y Troubleshooting**

```bash
# Ver errores recientes
curl "http://localhost:8000/api/v1/etl/errors?limit=10" | jq .

# Reprocessar tabla con errores
curl -X POST "http://localhost:8000/api/v1/etl/retry/services" | jq .

# Ver logs detallados
tail -f logs/etl_detailed.log | grep ERROR

# Test de conectividad BD
curl "http://localhost:8000/api/v1/etl/test-connection" | jq .
```

### **ğŸ“Š Reporting y Analytics**

```bash
# Reporte de calidad semanal
curl "http://localhost:8000/api/v1/etl/weekly-report" | jq .

# EstadÃ­sticas de KB growth
curl "http://localhost:8000/api/v1/etl/kb-growth-stats" | jq .

# Performance benchmarks
curl "http://localhost:8000/api/v1/etl/performance-report" | jq .
```

## ğŸ¯ **Casos de Uso Comunes**

### **ğŸ”„ Caso 1: Agregar Nueva Tabla a BD Existente**

```bash
# 1. Re-discover schema
curl -X POST "http://localhost:8000/api/v1/etl/rediscover" | jq .

# 2. Ver nueva tabla detectada
curl "http://localhost:8000/api/v1/etl/new-tables" | jq .

# 3. Evaluar con IA
curl -X POST "http://localhost:8000/api/v1/etl/evaluate-table/nueva_tabla" | jq .

# 4. Configurar si es relevante
curl -X PUT "http://localhost:8000/api/v1/etl/config/nueva_tabla" \
  -d '{"enabled": true, "priority": "MEDIA"}' | jq .
```

### **ğŸ”„ Caso 2: Migrar BD a Nuevo Servidor**

```bash
# 1. Actualizar variables de entorno
export MYSQL_HOST=nuevo-servidor.com

# 2. Test conectividad
curl "http://localhost:8000/api/v1/etl/test-connection" | jq .

# 3. Re-validar schema
curl -X POST "http://localhost:8000/api/v1/etl/validate-schema" | jq .

# 4. Sync completo desde nueva ubicaciÃ³n
curl -X POST "http://localhost:8000/api/v1/etl/full-resync" | jq .
```

### **ğŸ”„ Caso 3: Optimizar Performance**

```bash
# 1. Analizar bottlenecks
curl "http://localhost:8000/api/v1/etl/performance-analysis" | jq .

# 2. Ajustar batch sizes
curl -X PUT "http://localhost:8000/api/v1/etl/config/services" \
  -d '{"extraction": {"batch_size": 1000}}' | jq .

# 3. Optimizar horarios
curl -X PUT "http://localhost:8000/api/v1/etl/schedule" \
  -d '{"incremental_hours": 1, "full_sync_time": "01:00"}' | jq .
```

## ğŸ“‹ **Checklist de ImplementaciÃ³n**

### **âœ… Pre-ImplementaciÃ³n**
- [ ] Variables de entorno configuradas
- [ ] ConexiÃ³n BD validada
- [ ] Permisos de lectura confirmados
- [ ] Backup de configuraciones existentes

### **âœ… ImplementaciÃ³n**
- [ ] Context Extractor ejecutado
- [ ] DocumentaciÃ³n manual completada
- [ ] EvaluaciÃ³n IA revisada
- [ ] ConfiguraciÃ³n ETL ajustada
- [ ] Testing en tablas pequeÃ±as exitoso

### **âœ… Post-ImplementaciÃ³n**
- [ ] ETL completo ejecutado
- [ ] KB poblado correctamente
- [ ] TaxonomÃ­a auto-aprendida
- [ ] MÃ©tricas de calidad validadas
- [ ] Scheduler configurado
- [ ] Monitoring activo

### **âœ… Mantenimiento**
- [ ] DocumentaciÃ³n actualizada
- [ ] Reportes de calidad revisados
- [ ] Optimizaciones aplicadas
- [ ] Backup de configuraciones

## ğŸš¨ **Troubleshooting ComÃºn**

### **ğŸ”§ Problemas de ConexiÃ³n**
```bash
# Error: Connection refused
# SoluciÃ³n: Verificar host, puerto, credenciales
curl "http://localhost:8000/api/v1/etl/test-connection" | jq .
```

### **ğŸ”§ Problemas de Performance**
```bash
# Error: Timeout en ETL
# SoluciÃ³n: Reducir batch_size, optimizar queries
curl -X PUT "http://localhost:8000/api/v1/etl/config/tabla" \
  -d '{"extraction": {"batch_size": 100}}' | jq .
```

### **ğŸ”§ Problemas de Calidad**
```bash
# Error: Documentos de baja calidad
# SoluciÃ³n: Ajustar filtros, mejorar prompts IA
curl "http://localhost:8000/api/v1/etl/quality-report" | jq .
```

**Â¡Con esta guÃ­a completa, cualquier desarrollador puede implementar, mantener y escalar el sistema ETL Inteligente!** ğŸš€ğŸ“š
